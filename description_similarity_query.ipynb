{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "df = pd.read_csv(\"data/training_set.csv\")\n",
    "df_test = pd.read_csv(\"data/validation_set.csv\")\n",
    "\n",
    "df = df.sample(1000)\n",
    "df_test = df_test.sample(200)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HYDERABAD, India (AP) — At least 27 people were killed and dozens injured Tuesday in a stampede during a Hindu religious'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process descriptions\n",
    "descriptions = df[['Description']].reset_index()\n",
    "\n",
    "# Generate mapping between descriptions and indexes\n",
    "indices = pd.Series(descriptions.index, index=descriptions['Description']).drop_duplicates()\n",
    "\n",
    "sample_description = np.random.choice(descriptions['Description'])\n",
    "sample_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel \n",
    "\n",
    "def get_n_most_similar(description, cosine_sim, indices, n=10):\n",
    "    # Get index of movie that matches title\n",
    "    idx = indices[description]\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Get the scores for n most similar\n",
    "    sim_scores = sim_scores[1:n+1]\n",
    "    # Get most similar indices\n",
    "    similar_indices = [i[0] for i in sim_scores]\n",
    "    # Return the top 10 most similar \n",
    "    return descriptions['Description'].iloc[similar_indices]\n",
    "\n",
    "# Initialize the TfidfVectorizer \n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Construct the TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(descriptions['Description'])\n",
    "\n",
    "# Generate the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227    More than 300 people were killed in the attack...\n",
       "567    Rebekah Gregory was among those injured during...\n",
       "554           \"We’re not as few as people think we are.”\n",
       "814    More than half of U.S. women who die in gun ho...\n",
       "358    It might be useful to remember what other thre...\n",
       "366    It seems that everyone has taken a side follow...\n",
       "677    Once it became clear Tuesday night that Donald...\n",
       "743    Even before Donald Trump’s big win in New York...\n",
       "709    India has broken into the world top-five defen...\n",
       "208    \"We have hundreds of card partners and dozens ...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_most_similar(sample_description, cosine_sim, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim pretrained word embedding similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "documents = list(descriptions['Description'])\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set(stopwords.words('english'))\n",
    "\n",
    "texts = [\n",
    "    [word for word in word_tokenize(document) if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# remove words that appear only once ------------\n",
    "# this can be done with CountVectorizer I think\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "# ------------------------------------------------\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9037965 If we judge parents for putting their kids at very low risk, we could jail them for serving solid food (the child could choke!) letting them walk down stairs (the child could fall!) or permitting them to join a sport (concussions!).\n",
      "0.811677 Going green just got easier!\n",
      "0.78923297 They grow up so fast!\n",
      "0.7798173 Better Call Saul!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(835, 0.9037965), (90, 0.811677), (373, 0.78923297), (11, 0.7798173)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import models, similarities\n",
    "\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=15)\n",
    "\n",
    "def get_n_most_similar(doc, lsi, documents, n=10):\n",
    "    vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "    vec_lsi = lsi[vec_bow]  # convert the query to LSI space\n",
    "\n",
    "    # transform corpus to LSI space and index it\n",
    "    index = similarities.MatrixSimilarity(lsi[corpus])  \n",
    "\n",
    "    # perform a similarity query against the corpus\n",
    "    sims = sorted(enumerate(index[vec_lsi]), key=lambda item: -item[1])[:n]\n",
    "    for doc_position, doc_score in sims:\n",
    "        print(doc_score, documents[doc_position])\n",
    "    return sims\n",
    "\n",
    "get_n_most_similar(\"500 were killed\", lsi, documents, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiktor\\AppData\\Local\\Temp\\ipykernel_22180\\700410762.py:13: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  similarities[\"similarity\"] = similarities.text.apply(lambda x: doc.similarity(nlp(x)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>The aircraft, which carried 122 soldiers, fami...</td>\n",
       "      <td>0.924842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Statements from the two cops involved are so s...</td>\n",
       "      <td>0.924387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>There were no reports of injuries or deaths.</td>\n",
       "      <td>0.917251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Unlike the police, firefighters do not have a ...</td>\n",
       "      <td>0.914312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>At least 36 people died in the fire, and as ma...</td>\n",
       "      <td>0.913330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>After gunfire broke out on the anniversary of ...</td>\n",
       "      <td>0.911703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Another officer had been telling me about a re...</td>\n",
       "      <td>0.911656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>MakeSchool, which was originally named MakeGam...</td>\n",
       "      <td>0.909648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>When you see that the suicide rate has increas...</td>\n",
       "      <td>0.908378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>I use to think that not being friends with you...</td>\n",
       "      <td>0.905788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  similarity\n",
       "698  The aircraft, which carried 122 soldiers, fami...    0.924842\n",
       "305  Statements from the two cops involved are so s...    0.924387\n",
       "867       There were no reports of injuries or deaths.    0.917251\n",
       "901  Unlike the police, firefighters do not have a ...    0.914312\n",
       "550  At least 36 people died in the fire, and as ma...    0.913330\n",
       "788  After gunfire broke out on the anniversary of ...    0.911703\n",
       "619  Another officer had been telling me about a re...    0.911656\n",
       "900  MakeSchool, which was originally named MakeGam...    0.909648\n",
       "744  When you see that the suicide rate has increas...    0.908378\n",
       "196  I use to think that not being friends with you...    0.905788"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.nb.stop_words import STOP_WORDS as no_stopwords\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "nlp.Defaults.stop_words |= set(no_stopwords)\n",
    "nlp.Defaults.stop_words |= set([\"aker\", \"bp\",\"akerbp\"])\n",
    "\n",
    "def get_n_most_similar(text, texts, n=10):\n",
    "    doc = nlp(text)\n",
    "    similarities = pd.DataFrame({\"text\": texts})\n",
    "    similarities[\"similarity\"] = similarities.text.apply(lambda x: doc.similarity(nlp(x)))\n",
    "    similarities = similarities.sort_values(\"similarity\", ascending=False)\n",
    "    return similarities.head(n)\n",
    "    \n",
    "texts = list(descriptions['Description'])\n",
    "get_n_most_similar(\"500 people were killed. They tragically died in a storm.\", texts, n=10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a147fe3e9c6407a289b946e3945f04ff97327943be5259b126501dd191e22cc0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
